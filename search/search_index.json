{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"oncoexporter","text":"<p>Oncoexporter is a Python package that supports extract transform load (ETL) operations for patient data in translational research on oncology. Input data from sources such as Cancer Data Aggregator (CDA) are transformed into collections of GA4GH Phenopackets.</p> <p>The source code is available in the oncoexporter GitHub repository.</p>"},{"location":"#feedback","title":"Feedback","text":"<p>The best place to leave feedback, ask questions, and report bugs is the Oncoexporter Issue Tracker.</p>"},{"location":"installation/","title":"Installation","text":"<p>We will add this project to PyPI to ease installation. For now, a local installation is needed to run the notebooks. There are many ways of installing Python projects locally. We will explain several options here.</p>"},{"location":"installation/#install-into-virtual-environment","title":"Install into virtual environment","text":"<p>TBD</p>"},{"location":"installation/#create-a-virtual-environment","title":"Create a virtual environment","text":"<p>An optional first step is to create a virtual environment. Feel free to skip this if you already have a virtual environment which you want to use:</p> <pre><code>python3 -m venv oncoexporter-venv\nsource oncoexporter-venv/bin/activate\n</code></pre> <p>The command above will create a new virtual environment at <code>oncoexporter-venv</code> and activate the environment.</p>"},{"location":"installation/#install-oncoexporter","title":"Install Oncoexporter","text":"<p>Next, Oncoexporter can be installed into an existing virtual environment by running:</p> <pre><code> # Ensure you are in the repo folder\ncd oncoexporter\npython3 -m pip install --editable .\n</code></pre> <p><code>pip</code> will install <code>oncoexporter</code> into the active environment. The package is installed in editable mode - any code updates are available after Python restart, instead of having to reinstall.</p>"},{"location":"installation/#use-oncoexporter-in-jupyter-notebook","title":"Use Oncoexporter in Jupyter notebook","text":"<p>To use the kernel in Jupyter notebook, first, make sure you have <code>ipykernel</code> library to allow using the virtual environment as a Jupyter kernel.</p> <pre><code>python3 -m pip install jupyter ipykernel\n</code></pre> <p>Then, we can create a new Jupyter kernel and register the kernel with Jupyter by running:</p> <pre><code>python -m ipykernel install --user --name oncoexporter_env --display-name \"Oncoexporter\"\n</code></pre> <p>Last, starting from the project directory, we can run Jupyter to work on the notebooks of the Oncoexport repository.</p> <pre><code>cd notebooks\njupyter-notebook\n</code></pre> <p>At this point, a Jupyter page should open in the system browser. Navigate to the notebook or create one and be sure to activate the <code>oncoexporter_env</code> kernel.</p>"},{"location":"installation/#mkdocs-for-documentation","title":"mkdocs for documentation.","text":"<p>To run the mkdocs server locally, enter the following code to install prerequisites in the virtual environment</p> <pre><code>pip install mkdocs-material\npip install mkdocs-material[imaging]\npip install mkdocs-material-extensions\npip install pillow cairosvg\npip install mkdocstrings[python]\n</code></pre> <p>and then enter</p> <pre><code>mkdocs serve\n</code></pre> <p>This will serve the documentation site at http://127.0.0.1:8000/ and dynamically show changes. Merging to main will update the site on github IO.</p>"},{"location":"workplan/","title":"Work plan","text":"<p>The goal of this pilot project is to create a Python package that will simplify the encoding of oncology clinical data using the <code>GA4GH Phenopakcet Schema &lt;https://phenopacket-schema.readthedocs.io/en/latest/&gt;</code>_.</p> <p>The <code>pyphetools &lt;https://github.com/monarch-initiative/pyphetools&gt;</code>_ project has a comparable code base targeted a rare disease.</p> <p>This pilot project will use the API of the <code>CDA project &lt;https://github.com/CancerDataAggregator/cda-python.git&gt;</code> to access <code>Cancer Data Aggregator &lt;https://datacommons.cancer.gov/cancer-data-aggregator&gt;</code> resources, and output patient data using the Phenopacket Schema. The C2P code can then be extended to ingest data from other sources.</p>"},{"location":"workplan/#github-project-board","title":"GitHub project board","text":"<p>Let's use this project board to keep track of issues. The board is connected to the two repositories</p> <ul> <li>oncoexporter</li> <li>[]</li> </ul>"},{"location":"workplan/#work-items","title":"Work items","text":"<p>The first phase of work will be to provide and test ETL code to transform CDA data into collections of phenopackets.</p> <p>Let's use the following table to keep track of our status.</p> CDA ETL class Oncoexporter Class Status CdaIndividualFactory OpIndividual done, needs unit tests"},{"location":"cda/cda_biosample_factory/","title":"CdaBiosampleFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p>Class for creating a <code>Biosample</code> element from a row of the <code>specimen</code> CDA table.</p> <p>The class returns a GA4GH Biosample object that corresponds to a row of the speciment table. The CDA specimen table has the following fields.</p> <pre><code>- specimen_id: identifier\n- specimen_identifier: structured field with additional information\n- specimen_associated_project: e.g., CGCI-HTMCP-CC\n- days_to_collection: age in days at time specimen was collected\n- primary_disease_type: to be clarified\n- anatomical_site: body location at which specimen was collected\n- source_material_type: todo\n- specimen_type: todo\n- derived_from_specimen: todo\n- derived_from_subject: todo\n- subject_id: todo\n- researchsubject_id: todo\n</code></pre> Source code in <code>src/oncoexporter/cda/cda_biosample_factory.py</code> <pre><code>class CdaBiosampleFactory(CdaFactory):\n    \"\"\"\n    Class for creating a `Biosample` element from a row of the `specimen` CDA table.\n\n    The class returns a GA4GH Biosample object that corresponds to a row of the speciment table.\n    The CDA specimen table has the following fields.\n\n        - specimen_id: identifier\n        - specimen_identifier: structured field with additional information\n        - specimen_associated_project: e.g., CGCI-HTMCP-CC\n        - days_to_collection: age in days at time specimen was collected\n        - primary_disease_type: to be clarified\n        - anatomical_site: body location at which specimen was collected\n        - source_material_type: todo\n        - specimen_type: todo\n        - derived_from_specimen: todo\n        - derived_from_subject: todo\n        - subject_id: todo\n        - researchsubject_id: todo\n    \"\"\"\n\n    def to_ga4gh(self, row) -&gt; PPKt.Biosample:\n        biosample = PPKt.Biosample()\n\n        biosample.id = row['specimen_id']\n\n        derived_from_subj = row['derived_from_subject']\n        if derived_from_subj is not None:\n            biosample.individual_id = derived_from_subj\n\n        # TODO: Biosample time_of_collection: Age at time sample was collected\n        #  -&gt; need subject age + days to collection \n        #     perform this in cda_table_importer.py under \"Retrieve GA4GH Biospecimen messages\"\n        days_to_collection = row['days_to_collection'] # number of days from index date to sample collection date\n        if days_to_collection is not None:\n            pass\n            # need PPKt.iso8601duration where PPKt.OpIndividual.id = biosample.individual_id\n            # days_to_coll_td = pd.Timedelta(days=days_to_collection)\n            # time_of_coll = PPkt.iso8601duration + days_to_coll_td\n            # biosample.time_of_collection = time_of_coll.isoformat()\n\n        # derived_from_specimen -&gt; derived_from_id \n        '''\n        Under mapping specimen it says (for GDC): \"'specimen_type' is \"'sample' or 'portion' or 'slide' \n         or 'analyte' or 'aliquot'\" and \n         'derived_from_specimen' is \"'initial specimen' if specimen_type is 'sample'; \n         otherwise Specimen.id for parent Specimen record\".\n\n         Note: may want to add a check that specimen_type from CDA is 'sample' if derived_from is 'initial specimen'\n        '''\n        derived_from = row['derived_from_specimen']    \n        if derived_from is not None:  \n            if derived_from != 'initial specimen':  \n                biosample.derived_from_id = derived_from\n\n        # anatomical_site -&gt; sampled_tissue\n        sampled_tissue = _map_anatomical_site(row['anatomical_site'])\n        if sampled_tissue is not None:\n            biosample.sampled_tissue.CopyFrom(sampled_tissue)\n\n        sample_type = _map_specimen_type(row['specimen_type'])\n        if sample_type is not None:\n            biosample.sample_type.CopyFrom(sample_type)\n\n        biosample.taxonomy.CopyFrom(HOMO_SAPIENS)\n\n        # primary_disease_type -&gt; histological_diagnosis\n        histological_diagnosis = _map_primary_disease_type(row['primary_disease_type'])\n        if histological_diagnosis is not None:\n            biosample.histological_diagnosis.CopyFrom(histological_diagnosis)\n\n        material_sample = _map_source_material_type(row['source_material_type'])\n        if material_sample is not None:\n            biosample.material_sample.CopyFrom(material_sample)\n\n        return biosample\n</code></pre>"},{"location":"cda/cda_disease_factory/","title":"CdaDiseaseFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaDiseaseFactory</code> uses both the <code>diagnosis</code> and <code>researchsubject</code> tables to format the information about the disease diagnosis into the Disease element of the Phenopacket Schema.</p> <p>Note, <code>CdaDiseaseFactory</code> interprets the <code>age_at_diagnosis</code> as the age of onset.</p> <ul> <li>'primary_diagnosis'</li> <li>'primary_diagnosis_site'</li> <li>'primary_diagnosis_condition'</li> <li>'stage'</li> <li>'age_at_diagnosis'</li> </ul> <p>Parameters:</p> Name Type Description Default <code>disease_term_mapper</code> <code>OpMapper</code> <p>an :class:<code>OpMapper</code> for finding the disease term in the row fields.</p> required Source code in <code>src/oncoexporter/cda/cda_disease_factory.py</code> <pre><code>class CdaDiseaseFactory(CdaFactory):\n    \"\"\"\n    `CdaDiseaseFactory` uses both the `diagnosis` and `researchsubject` tables to format the information\n    about the disease diagnosis into the Disease element of the Phenopacket Schema.\n\n    Note, `CdaDiseaseFactory` interprets the `age_at_diagnosis` as the age of onset.\n\n    - 'primary_diagnosis'\n    - 'primary_diagnosis_site'\n    - 'primary_diagnosis_condition'\n    - 'stage'\n    - 'age_at_diagnosis'\n\n    :param disease_term_mapper: an :class:`OpMapper` for finding the disease term in the row fields.\n    \"\"\"\n\n    def __init__(self, disease_term_mapper: OpMapper):\n        self._disease_term_mapper = disease_term_mapper\n        self._stage_mapper = OpDiseaseStageMapper()\n        self._uberon_mapper = OpUberonMapper()\n\n        self._required_fields = tuple(set(itertools.chain(\n            self._disease_term_mapper.get_fields(),\n            self._stage_mapper.get_fields(),\n            self._uberon_mapper.get_fields(),\n            ('age_at_diagnosis',),\n        )))\n        # todo -- add in ICCDO Mapper\n\n\n    def to_ga4gh(self, row: pd.Series) -&gt; pp.Disease:\n        \"\"\"\n        Convert a row of the table obtained by merging CDA `diagnosis` and `researchsubject` tables into a Disease\n         message of the Phenopacket Schema.\n\n        The row is expected to contain the following columns:\n        - 'stage'\n        - 'primary_diagnosis_condition'\n        - 'primary_diagnosis_site'\n        - 'primary_diagnosis'\n        - 'age_at_diagnosis'\n\n        :param row: a :class:`pd.Series` with a row from the merged CDA table.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas Series but got {type(row)}\")\n\n        if any(field not in row for field in self._required_fields):\n            #missing = row.index.difference(self._required_fields) # this gets items in row not in _required_fields but we want the opposite\n            missing = []\n            print(row.index)\n            for i in self._required_fields:\n                print('i:', i)\n                if i not in row.index:\n                    print('not in row.index')\n                    missing.append(i)\n\n            raise ValueError(f'Required field(s) are missing: {missing}')\n\n        # This is the component we build here.\n        disease = pp.Disease()\n\n        term = self._disease_term_mapper.get_ontology_term(row=row)\n        if term is None:\n            # `term` is a required field.\n            raise ValueError(f'Could not parse `term` from the row {row}')\n        disease.term.CopyFrom(term)\n\n        # We will interpret age_at_diagnosis as age of onset\n\n        # raise ValueError(f\"days argument must be an int or a str but was {type(days)}\")\n        # ValueError: days argument must be an int or a str but was &lt;class 'pandas._libs.missing.NAType'&gt;\n        iso8601_age_of_onset = self.days_to_iso(str(row['age_at_diagnosis']))\n        if iso8601_age_of_onset is not None:\n            disease.onset.age.iso8601duration = iso8601_age_of_onset\n\n        # Deal with stage\n        stage = self._stage_mapper.get_ontology_term(row=row)\n        if stage is not None:\n            disease.disease_stage.append(stage)\n\n        primary_site = self._uberon_mapper.get_ontology_term(row)\n        if primary_site is not None:\n            disease.primary_site.CopyFrom(primary_site)\n\n        # Deal with morphology - clinical_tnm_finding_list seems like the most\n        # appropriate place to put this\n        # TODO -- work out where this goes. I do not think the ICDO will give us TNM\n        # clinical_tnm_finding_list = None #self._parse_morphology_into_ontology_term(row)\n\n        return disease\n</code></pre>"},{"location":"cda/cda_disease_factory/#src.oncoexporter.cda.CdaDiseaseFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>Convert a row of the table obtained by merging CDA <code>diagnosis</code> and <code>researchsubject</code> tables into a Disease  message of the Phenopacket Schema.</p> <p>The row is expected to contain the following columns: - 'stage' - 'primary_diagnosis_condition' - 'primary_diagnosis_site' - 'primary_diagnosis' - 'age_at_diagnosis'</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a :class:<code>pd.Series</code> with a row from the merged CDA table.</p> required Source code in <code>src/oncoexporter/cda/cda_disease_factory.py</code> <pre><code>def to_ga4gh(self, row: pd.Series) -&gt; pp.Disease:\n    \"\"\"\n    Convert a row of the table obtained by merging CDA `diagnosis` and `researchsubject` tables into a Disease\n     message of the Phenopacket Schema.\n\n    The row is expected to contain the following columns:\n    - 'stage'\n    - 'primary_diagnosis_condition'\n    - 'primary_diagnosis_site'\n    - 'primary_diagnosis'\n    - 'age_at_diagnosis'\n\n    :param row: a :class:`pd.Series` with a row from the merged CDA table.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas Series but got {type(row)}\")\n\n    if any(field not in row for field in self._required_fields):\n        #missing = row.index.difference(self._required_fields) # this gets items in row not in _required_fields but we want the opposite\n        missing = []\n        print(row.index)\n        for i in self._required_fields:\n            print('i:', i)\n            if i not in row.index:\n                print('not in row.index')\n                missing.append(i)\n\n        raise ValueError(f'Required field(s) are missing: {missing}')\n\n    # This is the component we build here.\n    disease = pp.Disease()\n\n    term = self._disease_term_mapper.get_ontology_term(row=row)\n    if term is None:\n        # `term` is a required field.\n        raise ValueError(f'Could not parse `term` from the row {row}')\n    disease.term.CopyFrom(term)\n\n    # We will interpret age_at_diagnosis as age of onset\n\n    # raise ValueError(f\"days argument must be an int or a str but was {type(days)}\")\n    # ValueError: days argument must be an int or a str but was &lt;class 'pandas._libs.missing.NAType'&gt;\n    iso8601_age_of_onset = self.days_to_iso(str(row['age_at_diagnosis']))\n    if iso8601_age_of_onset is not None:\n        disease.onset.age.iso8601duration = iso8601_age_of_onset\n\n    # Deal with stage\n    stage = self._stage_mapper.get_ontology_term(row=row)\n    if stage is not None:\n        disease.disease_stage.append(stage)\n\n    primary_site = self._uberon_mapper.get_ontology_term(row)\n    if primary_site is not None:\n        disease.primary_site.CopyFrom(primary_site)\n\n    # Deal with morphology - clinical_tnm_finding_list seems like the most\n    # appropriate place to put this\n    # TODO -- work out where this goes. I do not think the ICDO will give us TNM\n    # clinical_tnm_finding_list = None #self._parse_morphology_into_ontology_term(row)\n\n    return disease\n</code></pre>"},{"location":"cda/cda_factory/","title":"CdaFactory","text":"<p>TODO Add statement to include API information. For some reason, mkdocs is not picking this up.</p>"},{"location":"cda/cda_factory/#srconcoexportercdacdafactory","title":"src.oncoexporter.cda.CdaFactory","text":""},{"location":"cda/cda_individual_factory/","title":"CdaIndividualFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaIndividualFactory</code> creates a GA4GH individual messages from a row of the CDA subject table.</p> <p>The structure of the CDA subject table is as follows:</p> <pre><code>- subject_id (*)\n- subject_identifier\n- species\n- sex (*)\n- race\n- ethnicity\n- days_to_birth (*)\n- subject_associated_project\n- vital_status (*)\n- days_to_death (*)\n- cause_of_death (*)\n</code></pre> <p>(*) indicates a used field.</p> Source code in <code>src/oncoexporter/cda/cda_individual_factory.py</code> <pre><code>class CdaIndividualFactory(CdaFactory):\n    \"\"\"\n    `CdaIndividualFactory` creates a GA4GH individual messages from a row of the CDA *subject* table.\n\n    The structure of the CDA subject table is as follows:\n\n        - subject_id (*)\n        - subject_identifier\n        - species\n        - sex (*)\n        - race\n        - ethnicity\n        - days_to_birth (*)\n        - subject_associated_project\n        - vital_status (*)\n        - days_to_death (*)\n        - cause_of_death (*)\n\n    (*) indicates a used field.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._cause_of_death_mapper = OpCauseOfDeathMapper()\n        self._male_sex = {'m', 'male'}\n        self._female_sex = {'f', 'female'}\n\n    def _process_vital_status(self, row: pd.Series):\n        \"\"\"\n        :param row: a row from the CDA subject table\n        :type row: pd.Series\n        :returns: A vital status object with information about cause of death if applicable.\n        :rtype: PPkt.VitalStatus\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"'row' argument must be pandas Series but was {type(row)}\")\n        vital_status = self.get_item(row, \"vital_status\")\n        days_to_death = self.get_item(row, \"days_to_death\")\n        if vital_status is None:\n            return None\n        valid_status = {\"Alive\", \"Dead\"}\n        if vital_status not in valid_status:\n            return None\n        vstatus = PPkt.VitalStatus()\n        if vital_status == \"Alive\":\n            vstatus.status = PPkt.VitalStatus.ALIVE\n        elif vital_status == \"Dead\":\n            vstatus.status = PPkt.VitalStatus.DECEASED\n        if days_to_death is not None:\n            try:\n                dtd = int(days_to_death)\n                vstatus.survival_time_in_days = dtd\n            except:\n                # TODO: report?\n                pass\n        cause = self._cause_of_death_mapper.get_ontology_term(row)\n        if cause is not None:\n            vstatus.cause_of_death.CopyFrom(cause)\n        return vstatus\n\n    def to_ga4gh(self, row:pd.Series):\n        \"\"\"\n        convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)\n\n        :param row: a row from the CDA subject table\n        :type row: pd.Series\n        :returns: A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.\n        :rtype: PPkt.Individual\n        :raises ValueError: if the input is unparsable.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n        row = row.astype(str)\n        subject_id = row['subject_id']\n        # subject_identifier = row['subject_identifier']\n        # species = row['species']\n        sex = row['sex']\n        # race = row['race']\n        # ethnicity = row['ethnicity']\n        days_to_birth = row['days_to_birth']\n        # a valid date looks like this: '-15987.0'\n        if days_to_birth.startswith(\"-\"):\n            days_to_birth = days_to_birth[1:]\n        iso_age = None\n        vstat = None\n        try:\n            # we need to parse '15987.0' first as a float and then transform to int\n            d_to_b = int(float(days_to_birth))\n            iso_age = self.days_to_iso(days=d_to_b)\n            vstat = self._process_vital_status(row)\n        except Exception:\n            # TODO: handle in a better way\n            pass\n        # subject_associated_project = row['subject_associated_project']\n\n\n        individual = PPkt.Individual()\n        individual.id = subject_id\n\n        # time_at_last_encounter\n        if iso_age is not None:\n            individual.time_at_last_encounter.age.iso8601duration = iso_age\n\n        # vital status\n        if vstat is not None:\n            individual.vital_status.CopyFrom(vstat)\n\n        # sex\n        if sex in self._male_sex:\n            individual.sex = PPkt.MALE\n        elif sex in self._female_sex:\n            individual.sex = PPkt.FEMALE\n        else:\n            individual.sex = PPkt.UNKNOWN_SEX\n\n        # taxonomy, always Homo here\n        individual.taxonomy.id = \"NCBITaxon:9606\"\n        individual.taxonomy.label = \"Homo sapiens\"\n\n        return individual\n</code></pre>"},{"location":"cda/cda_individual_factory/#src.oncoexporter.cda.CdaIndividualFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a row from the CDA subject table</p> required <p>Returns:</p> Type Description <code>PPkt.Individual</code> <p>A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the input is unparsable.</p> Source code in <code>src/oncoexporter/cda/cda_individual_factory.py</code> <pre><code>def to_ga4gh(self, row:pd.Series):\n    \"\"\"\n    convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)\n\n    :param row: a row from the CDA subject table\n    :type row: pd.Series\n    :returns: A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.\n    :rtype: PPkt.Individual\n    :raises ValueError: if the input is unparsable.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n    row = row.astype(str)\n    subject_id = row['subject_id']\n    # subject_identifier = row['subject_identifier']\n    # species = row['species']\n    sex = row['sex']\n    # race = row['race']\n    # ethnicity = row['ethnicity']\n    days_to_birth = row['days_to_birth']\n    # a valid date looks like this: '-15987.0'\n    if days_to_birth.startswith(\"-\"):\n        days_to_birth = days_to_birth[1:]\n    iso_age = None\n    vstat = None\n    try:\n        # we need to parse '15987.0' first as a float and then transform to int\n        d_to_b = int(float(days_to_birth))\n        iso_age = self.days_to_iso(days=d_to_b)\n        vstat = self._process_vital_status(row)\n    except Exception:\n        # TODO: handle in a better way\n        pass\n    # subject_associated_project = row['subject_associated_project']\n\n\n    individual = PPkt.Individual()\n    individual.id = subject_id\n\n    # time_at_last_encounter\n    if iso_age is not None:\n        individual.time_at_last_encounter.age.iso8601duration = iso_age\n\n    # vital status\n    if vstat is not None:\n        individual.vital_status.CopyFrom(vstat)\n\n    # sex\n    if sex in self._male_sex:\n        individual.sex = PPkt.MALE\n    elif sex in self._female_sex:\n        individual.sex = PPkt.FEMALE\n    else:\n        individual.sex = PPkt.UNKNOWN_SEX\n\n    # taxonomy, always Homo here\n    individual.taxonomy.id = \"NCBITaxon:9606\"\n    individual.taxonomy.label = \"Homo sapiens\"\n\n    return individual\n</code></pre>"},{"location":"cda/cda_mutation_factory/","title":"CdaMutationFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaMutationFactory</code> maps a row of the CDA mutation table into <code>VariantInterpretation</code> element of the Phenopacket Schema.</p> <p>See <code>here &lt;https://cda.readthedocs.io/en/latest/Schema/fields_mutation/&gt;</code>_ for the mutation table schema.</p> <p>Initial fields to map to phenopackets: - cda_subject_id - Entrez_Gene_Id - Hugo_Symbol - NCBI_Build - Chromosome - Start_Position - End_Position - Reference_Allele - Tumor_Seq_Allele2 - dbSNP_RS - Transcript_ID - HGVSc - ENSP - HGVSp_Short - Mutation_Status - t_depth - t_ref_count - t_alt_count - n_depth - n_ref_count - n_alt_count</p> <p>Additional fields to map, not required for pilot: - primary_site - dbSNP_Val_Status - HGVSp - Match_Norm_Seq_Allele1 - Match_Norm_Seq_Allele2 - Tumor_Validation_Allele1 - Tumor_Validation_Allele2 - Match_Norm_Validation_Allele1 - Match_Norm_Validation_Allele2</p> Source code in <code>src/oncoexporter/cda/cda_mutation_factory.py</code> <pre><code>class CdaMutationFactory(CdaFactory):\n    \"\"\"\n    `CdaMutationFactory` maps a row of the CDA mutation table into `VariantInterpretation`\n    element of the Phenopacket Schema.\n\n    See `here &lt;https://cda.readthedocs.io/en/latest/Schema/fields_mutation/&gt;`_ for\n    the mutation table schema.\n\n    Initial fields to map to phenopackets:\n    - cda_subject_id\n    - Entrez_Gene_Id\n    - Hugo_Symbol\n    - NCBI_Build\n    - Chromosome\n    - Start_Position\n    - End_Position\n    - Reference_Allele\n    - Tumor_Seq_Allele2\n    - dbSNP_RS\n    - Transcript_ID\n    - HGVSc\n    - ENSP\n    - HGVSp_Short\n    - Mutation_Status\n    - t_depth\n    - t_ref_count\n    - t_alt_count\n    - n_depth\n    - n_ref_count\n    - n_alt_count\n\n    Additional fields to map, not required for pilot:\n    - primary_site\n    - dbSNP_Val_Status\n    - HGVSp\n    - Match_Norm_Seq_Allele1\n    - Match_Norm_Seq_Allele2\n    - Tumor_Validation_Allele1\n    - Tumor_Validation_Allele2\n    - Match_Norm_Validation_Allele1\n    - Match_Norm_Validation_Allele2\n    \"\"\"\n\n    def __init__(self):\n        self._column_names = [\n            'Entrez_Gene_Id', 'Hugo_Symbol',\n            'NCBI_Build', 'Chromosome', 'Start_Position', 'End_Position', 'Reference_Allele', 'Tumor_Seq_Allele2',\n            'dbSNP_RS',\n            'Transcript_ID', 'HGVSc', 'ENSP', 'HGVSp_Short',\n            'Mutation_Status',\n            't_depth', 't_ref_count', 't_alt_count',\n            'n_depth', 'n_ref_count', 'n_alt_count',\n        ]\n        self._logger = logging.getLogger(__name__)\n\n    def to_ga4gh(self, row: pd.Series) -&gt; pp.VariantInterpretation:\n        \"\"\"\n        Convert a row from the CDA mutation table\n        into a VariantInterpretation message (GA4GH Phenopacket Schema).\n\n        :param row: a :class:`pd.Series` with the row of the CDA mutation table.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n\n        if any(field not in row for field in self._column_names):\n            keys = set(row.index)\n            missing = keys.difference(self._column_names)\n            raise ValueError(f'Missing field(s): {missing}')\n\n\n        vdescriptor = pp.VariationDescriptor()\n\n        vdescriptor.id = self._generate_id(row)\n\n        # Gene context\n        if row['Hugo_Symbol'] is not None and row['Entrez_Gene_Id'] is not None:\n            vdescriptor.gene_context.value_id = f\"NCBIGene:{row['Entrez_Gene_Id']}\"\n            vdescriptor.gene_context.symbol = row['Hugo_Symbol']\n\n        # We may consider including an HGVS c expression for ALL transcripts,\n        # using the `all_effects` field that looks like this:\n        # SPRY3,missense_variant,p.G118A,ENST00000302805,NM_005840.2,c.353G&gt;C,MODERATE,YES,deleterious(0),benign(0.001),1;SPRY3,missense_variant,p.G118A,ENST00000675360,NM_001304990.1,c.353G&gt;C,MODERATE,,deleterious(0),benign(0.001),1\n        if row['Transcript_ID'] is not None and row['HGVSc'] is not None:\n            hgvs_expression = pp.Expression()\n            hgvs_expression.syntax = \"hgvs.c\"\n            hgvs_expression.value = f\"{row['Transcript_ID']}:{row['HGVSc']}\"\n            vdescriptor.expressions.append(hgvs_expression)\n\n        if row['ENSP'] is not None and row['HGVSp_Short'] is not None:\n            hgvs_expression = pp.Expression()\n            hgvs_expression.syntax = \"hgvs.p\"\n            hgvs_expression.value = f\"{row['ENSP']}:{row['HGVSp_Short']}\"\n            vdescriptor.expressions.append(hgvs_expression)\n\n        # TODO: consider adding HGVS.g\n\n        vcf_record = self._create_vcf_record(row)\n        if vcf_record is not None:\n            vdescriptor.vcf_record.CopyFrom(vcf_record)\n\n        # Tumor/normal depths\n        for name in ('t_depth', 't_ref_count', 't_alt_count',\n                     'n_depth', 'n_ref_count', 'n_alt_count'):\n            val = row[name]\n            ext = pp.Extension()\n            ext.name = name\n            # We expect an `int` or `None`.\n            ext.value = str(val)\n            vdescriptor.extensions.append(ext)\n\n        # Mutation status\n        ms = row['Mutation_Status']\n        if ms is not None and len(ms) &gt; 1:\n            ext = pp.Extension()\n            ext.name = 'Mutation_Status'\n            ext.value = ms\n            vdescriptor.extensions.append(ext)\n\n        vdescriptor.molecule_context = pp.MoleculeContext.genomic\n\n        vinterpretation = pp.VariantInterpretation()\n        vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n        return vinterpretation\n\n    def _create_vcf_record(self, row: pd.Series) -&gt; typing.Optional[pp.VcfRecord]:\n        ref = row['Reference_Allele']\n        alt = row['Tumor_Seq_Allele2']\n        if ref == '-' or alt == '-':\n            self._logger.debug(\n                'Cannot create a VCF record due to missing bases in the Reference_Allele/Tumor_Seq_Allele2 alleles: %s',\n                row)\n            return None\n\n        vcf_record = pp.VcfRecord()\n        vcf_record.genome_assembly = row['NCBI_Build']\n        vcf_record.chrom = row['Chromosome']\n        rs_id = row['dbSNP_RS']\n        if rs_id is not None:\n            vcf_record.id = rs_id\n        vcf_record.pos = row['Start_Position']\n        vcf_record.ref = ref\n        vcf_record.alt = alt\n        return vcf_record\n\n    @staticmethod\n    def _generate_id(row: pd.Series) -&gt; str:\n        return str(hash(''.join(str(x) for x in row.values)))\n</code></pre>"},{"location":"cda/cda_mutation_factory/#src.oncoexporter.cda.CdaMutationFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>Convert a row from the CDA mutation table into a VariantInterpretation message (GA4GH Phenopacket Schema).</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a :class:<code>pd.Series</code> with the row of the CDA mutation table.</p> required Source code in <code>src/oncoexporter/cda/cda_mutation_factory.py</code> <pre><code>def to_ga4gh(self, row: pd.Series) -&gt; pp.VariantInterpretation:\n    \"\"\"\n    Convert a row from the CDA mutation table\n    into a VariantInterpretation message (GA4GH Phenopacket Schema).\n\n    :param row: a :class:`pd.Series` with the row of the CDA mutation table.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n\n    if any(field not in row for field in self._column_names):\n        keys = set(row.index)\n        missing = keys.difference(self._column_names)\n        raise ValueError(f'Missing field(s): {missing}')\n\n\n    vdescriptor = pp.VariationDescriptor()\n\n    vdescriptor.id = self._generate_id(row)\n\n    # Gene context\n    if row['Hugo_Symbol'] is not None and row['Entrez_Gene_Id'] is not None:\n        vdescriptor.gene_context.value_id = f\"NCBIGene:{row['Entrez_Gene_Id']}\"\n        vdescriptor.gene_context.symbol = row['Hugo_Symbol']\n\n    # We may consider including an HGVS c expression for ALL transcripts,\n    # using the `all_effects` field that looks like this:\n    # SPRY3,missense_variant,p.G118A,ENST00000302805,NM_005840.2,c.353G&gt;C,MODERATE,YES,deleterious(0),benign(0.001),1;SPRY3,missense_variant,p.G118A,ENST00000675360,NM_001304990.1,c.353G&gt;C,MODERATE,,deleterious(0),benign(0.001),1\n    if row['Transcript_ID'] is not None and row['HGVSc'] is not None:\n        hgvs_expression = pp.Expression()\n        hgvs_expression.syntax = \"hgvs.c\"\n        hgvs_expression.value = f\"{row['Transcript_ID']}:{row['HGVSc']}\"\n        vdescriptor.expressions.append(hgvs_expression)\n\n    if row['ENSP'] is not None and row['HGVSp_Short'] is not None:\n        hgvs_expression = pp.Expression()\n        hgvs_expression.syntax = \"hgvs.p\"\n        hgvs_expression.value = f\"{row['ENSP']}:{row['HGVSp_Short']}\"\n        vdescriptor.expressions.append(hgvs_expression)\n\n    # TODO: consider adding HGVS.g\n\n    vcf_record = self._create_vcf_record(row)\n    if vcf_record is not None:\n        vdescriptor.vcf_record.CopyFrom(vcf_record)\n\n    # Tumor/normal depths\n    for name in ('t_depth', 't_ref_count', 't_alt_count',\n                 'n_depth', 'n_ref_count', 'n_alt_count'):\n        val = row[name]\n        ext = pp.Extension()\n        ext.name = name\n        # We expect an `int` or `None`.\n        ext.value = str(val)\n        vdescriptor.extensions.append(ext)\n\n    # Mutation status\n    ms = row['Mutation_Status']\n    if ms is not None and len(ms) &gt; 1:\n        ext = pp.Extension()\n        ext.name = 'Mutation_Status'\n        ext.value = ms\n        vdescriptor.extensions.append(ext)\n\n    vdescriptor.molecule_context = pp.MoleculeContext.genomic\n\n    vinterpretation = pp.VariantInterpretation()\n    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n    return vinterpretation\n</code></pre>"},{"location":"cda/cda_table_importer/","title":"CdaTableImporter","text":"<p>               Bases: <code>CdaImporter[fetch_rows]</code></p> <p>This class is the entry point for transforming CDA data into GA4GH Phenopackets. Client code only needs to initialize it with a CDA query, and it can return phenopackets with the :func:<code>get_ga4gh_phenopackets</code>. It also returns individual tables for that can be used for testing or visualizing data.</p> <p>The CDA query determines the cohort that will be retrieved from CDA. This class then retrieves data for this cohort in form of pandas DataFrames and extracts data for phenopacket construction using the data in the tables</p> <p>Parameters:</p> Name Type Description Default <code>disease_factory</code> <code>CdaDiseaseFactory</code> <p>the component for mapping CDA table into Disease element of the Phenopacket Schema.</p> required <code>cache_dir</code> <code>Optional[str]</code> <p>a <code>str</code> with path to the folder to store the cache files</p> <code>None</code> <code>use_cache</code> <code>bool</code> <p>if True, cache/retrieve from cache</p> <code>False</code> <code>page_size</code> <p>Number of pages to retrieve at once. Defaults to <code>10000</code>  New CDA:  https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#returning-a-matrix-of-results old: all of the functions previously used with, or chained onto Q()...run() have been replaced with the single function fetch_rows() new: `fetch_rows(table=, )  https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#parameters old: page_size, limit, and count parameters have been removed new: column_values always returns all unique values and their counts by default, however there are several new parameters  old: system= new: data_source= can now take a list, as in data_source=[\"GDC\", \"PDC\"]  new: sort_by= sort results by any column  new: force= For columns with an extremely large number of unique values, such as filename, the query will fail with a large data warning. You can override the warning with Force=True  tables: ['diagnosis', 'file', 'researchsubject', 'somatic_mutation', 'specimen', 'subject', 'treatment'] required Source code in <code>src/oncoexporter/cda/cda_table_importer.py</code> <pre><code>class CdaTableImporter(CdaImporter[fetch_rows]):\n    \"\"\"This class is the entry point for transforming CDA data into GA4GH Phenopackets. Client code only needs\n    to initialize it with a CDA query, and it can return phenopackets with the :func:`get_ga4gh_phenopackets`.\n    It also returns individual tables for that can be used for testing or visualizing data.\n\n    The CDA query determines the cohort that will be retrieved from CDA. This class then retrieves data\n    for this cohort in form of pandas DataFrames and extracts data for phenopacket construction using the data\n    in the tables\n\n    :param disease_factory: the component for mapping CDA table into Disease element of the Phenopacket Schema.\n    :param cache_dir: a `str` with path to the folder to store the cache files\n    :param use_cache: if True, cache/retrieve from cache\n    :param page_size: Number of pages to retrieve at once. Defaults to `10000`\n\n    New CDA: \n    https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#returning-a-matrix-of-results\n    old: all of the functions previously used with, or chained onto Q()...run() have been replaced with the single function fetch_rows()\n    new: `fetch_rows(table=, )\n\n    https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#parameters\n    old: page_size, limit, and count parameters have been removed\n    new: column_values always returns all unique values and their counts by default, however there are several new parameters\n\n    old: system=&lt;data source&gt;\n    new: data_source=&lt;data source&gt; can now take a list, as in data_source=[\"GDC\", \"PDC\"]\n\n    new: sort_by=&lt;column:asc/desc&gt; sort results by any column\n\n    new: force=&lt;True/False&gt; For columns with an extremely large number of unique values, such as filename, the query will fail with a large data warning. You can override the warning with Force=True\n\n    tables: ['diagnosis', 'file', 'researchsubject', 'somatic_mutation', 'specimen', 'subject', 'treatment']\n    \"\"\"\n\n    def __init__(self,\n                 disease_factory: CdaDiseaseFactory,\n                 use_cache: bool = False,\n                 cache_dir: typing.Optional[str] = None,\n                 #page_size: int = 10000,\n                 gdc_timeout: int = 100000,\n                 ):\n        self._use_cache = use_cache\n        #self._page_size = page_size # not in new CDA \n\n        self._individual_factory = CdaIndividualFactory()\n        self._disease_factory = disease_factory\n        self._specimen_factory = CdaBiosampleFactory()\n        self._mutation_factory = CdaMutationFactory()\n        self._gdc_mutation_service = GdcMutationService(timeout=gdc_timeout)\n\n        if cache_dir is None:\n            self._cache_dir = os.path.join(os.getcwd(), '.oncoexporter_cache')\n            if not os.path.isdir(self._cache_dir):\n                os.makedirs(self._cache_dir, exist_ok=True)\n        else:\n            if not os.path.isdir(cache_dir) or not os.access(cache_dir, os.W_OK):\n                raise ValueError(f'`cache_dir` must be a writable directory: {cache_dir}')\n\n    def _get_cda_df(self, callback_fxn, cache_name: str):\n        fpath_cache = os.path.join(self._cache_dir, cache_name)\n        if self._use_cache and os.path.isfile(fpath_cache):\n            print(f\"\\tRetrieving dataframe {fpath_cache}\")\n            with open(fpath_cache, 'rb') as cachehandle:\n                print(f\"loading cached dataframe from {fpath_cache}\")\n                individual_df = pickle.load(cachehandle)\n        else:\n            print(f\"\\tcalling CDA function\")\n            individual_df = callback_fxn()\n            if self._use_cache:\n                print(f\"Creating cached dataframe as {fpath_cache}\")\n                with open(fpath_cache, 'wb') as f:\n                    pickle.dump(individual_df, f)\n        return individual_df\n\n    # not clear why this is _ but others are not...\n    def _get_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"Retrieve the subject dataframe from CDA\n\n        This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n        :raises: raises an exception if the query object was not properly initialized\n        :returns: pandas DataFrame that corresponds to the CDA subject table.\n        :rtype: pd.DataFrame\n        \"\"\"\n        print(\"\\nGetting subject df...\")\n        #callable = lambda: q.subject.run(page_size=self._page_size).get_all().to_dataframe()\n        callable = lambda: fetch_rows( table='subject', **q )\n        subject_df = self._get_cda_df(callable, f\"{cohort_name}_individual_df.pkl\")\n        print(\"obtained subject_df\")\n        return subject_df\n\n    def get_merged_diagnosis_research_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Retrieve a merged dataframe from CDA corresponding to the diagnosis and research subject tables\n\n        diagnosis table columns: diagnosis_id, age_at_diagnosis, grade, method_of_diagnosis, morphology, primary_diagnosis, stage\n\n        researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition, primary_diagnosis_site\n\n        Need to combine in order to get primary_diagnosis_condition and primary_diagnosis_site with diagnosis table\n\n        Original:\n        diagnosis_callable = lambda: q.diagnosis.run(page_size=self._page_size).get_all().to_dataframe()\n        diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\")\n        print(\"obtained diagnosis_df\")\n\n        rsub_callable = lambda: q.researchsubject.run(page_size=self._page_size).get_all().to_dataframe()\n        research_subject_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_research_subject_df.pkl\")\n        print(\"obtained research_subject_df\")\n\n        merged_df = pd.merge(diagnosis_df, research_subject_df, left_on='researchsubject_id', right_on='researchsubject_id',\n                             suffixes=[\"_di\", \"_rs\"])\n        return merged_df\n\n        \"\"\"\n        print(\"\\nGetting merged diagnosis and researchsubject df...\")\n        diagnosis_callable = lambda: fetch_rows( table='diagnosis', **q , add_columns=['subject_id'])\n        diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\")\n        print(\"obtained diagnosis_df\")\n        #diagnosis_df.to_csv('diagnosis_df.txt', sep='\\t')\n\n        # tried link_to_table='diagnosis' but it doesn't add any columns\n        rsub_callable = lambda: fetch_rows( table='researchsubject', **q , add_columns=['subject_id'])\n        rsub_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_researchsubject_df.pkl\") # call is repeated below in get_merged_subject_research_subject_df\n        print(\"obtained researchsubject_df\")\n        #rsub_df.to_csv('rsub_diagnosis_df.txt', sep='\\t')\n\n        # merge tables\n        diag_rsub_df = pd.merge(diagnosis_df, rsub_df, left_on='subject_id', right_on='subject_id') #, suffixes=[\"_di\", \"_rs\"])\n        print(\"obtained merged diagnosis researchsubject df\")\n        #diag_rsub_df.to_csv('diagnosis_rsub.txt', sep='\\t')\n\n        return diag_rsub_df\n\n    def get_merged_subject_research_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Retrieve a merged dataframe from CDA corresponding to the subject and research subject tables\n        Need both subject_id and researchsubject_id to include variants in phenopacket \n\n        subject table columns: subject_id, cause_of_death, days_to_birth, days_to_death, ethnicity, race\n                               sex, species, vital_status\n\n        researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition, \n                                        primary_diagnosis_site\n\n        M. Sierk 4-11-24: \n            This is how Henry Schaeffer from CBIIT recommended getting the data source:\n\n            I consolidate the data_source_id columns (as opposed to just deleting it which works also) or else \n            the merge expands each subject into many more rows. For example, for subject provenance I used:\n\n            sub = fetch_rows(table='subject', provenance=True)\n            sub['subject_data_source_id_concat'] = sub.groupby(['subject_id','subject_data_source'])['subject_data_source_id'].transform(lambda x: ','.join(x))\n            sub = sub.drop(columns=['subject_data_source_id'], axis=1)\n            sub = sub.drop_duplicates()\n\n        \"\"\"\n        print(\"\\nGetting merged subject and researchsubject df...\")\n        #subject_callable = lambda: q.subject.run(page_size=self._page_size).get_all().to_dataframe()\n\n        subject_callable = lambda: fetch_rows( table='subject', **q ) # link_to_table='researchsubject' doesn't add anything\n        subject_df = self._get_cda_df(subject_callable, f\"{cohort_name}_subject_df.pkl\")\n\n        rsub_callable = lambda: fetch_rows( table='researchsubject', **q , add_columns=['subject_id']) # repeat from above\n        rsub_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_researchsubject_df.pkl\")\n\n        # merge tables\n        subject_rsub_df = pd.merge(subject_df, rsub_df, left_on='subject_id', right_on='subject_id') #, suffixes=[\"_di\", \"_rs\"])\n        print(\"obtained merged subject and researchsubject df\")\n        #subject_rsub_df.to_csv('subject_rsub_df.txt', sep='\\t')\n\n\n        #rsub_callable = lambda: q.researchsubject.run(page_size=self._page_size).get_all().to_dataframe()\n        #rsub_callable = lambda: fetch_rows( table='researchsubject', **q , link_to_table='subject' )\n        #research_subject_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_research_subject_df.pkl\")\n        #print(\"obtained research_subject_df\")\n        #merged_df = pd.merge(subject_df, research_subject_df, left_on='subject_id', right_on='subject_id',\n                                #suffixes=[\"_subj\", \"_rs\"])\n        #research_subject_df.to_csv('researchsubject_df.txt', sep='\\t')\n\n        return subject_rsub_df\n\n    def get_specimen_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"Retrieve the subject dataframe from CDA\n\n        This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n        :raises: raises an exception if the query object was not properly initialized\n        :returns: pandas DataFrame that corresponds to the CDA subject table.\n        :rtype: pd.DataFrame\n        \"\"\"\n        print(\"\\nGetting specimen df...\")\n        #specimen_callable = lambda: q.specimen.run(page_size=self._page_size).get_all().to_dataframe()\n        specimen_callable = lambda: fetch_rows( table='specimen', **q, add_columns=['subject_id'] )\n        specimen_df = self._get_cda_df(specimen_callable, f\"{cohort_name}_specimen_df.pkl\")\n        #specimen_df.to_csv('specimen_df.txt', sep='\\t')\n        return specimen_df\n\n    def get_treatment_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        print(\"\\nGetting treatment df...\")\n        #treatment_callable = lambda: q.treatment.run(page_size=self._page_size).get_all().to_dataframe()\n        treatment_callable = lambda: fetch_rows( table='treatment', **q, add_columns=['subject_id'] )\n        treatment_df = self._get_cda_df(treatment_callable, f\"{cohort_name}_treatment_df.pkl\")\n        #treatment_df.to_csv('treatment_df.txt', sep='\\t')\n        return treatment_df\n\n    def get_ga4gh_phenopackets(self, source: dict, **kwargs) -&gt; typing.List[PPkt.Phenopacket]:\n        \"\"\"Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.\n\n        :returns: A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.\n        :rtype: typing.List[PPkt.Phenopacket]\n\n        New version of CDA: need to change Q to fetch_rows()\n        \"\"\"\n        # no longer using Q objects\n        # if not isinstance(source, Q):\n        #    raise ValueError(f\"query_obj argument must be Q.Q object, but instead was {type(source)}\")\n\n        if 'cohort_name' in kwargs:\n            cohort_name = kwargs['cohort_name']\n        else:\n            # Format it as a string, for example: 'YYYY-MM-DD HH:MM:SS'\n            ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            cohort_name = f'cohort-{ts}'\n\n        # Dictionary of phenopackets, keys are the phenopacket ids.\n        ppackt_d = {}\n\n        # First obtain the pandas DataFrames from the CDA tables with rows that correspond to the Query\n        subject_df = self._get_subject_df(source, cohort_name)\n        diag_rsub_df = self.get_merged_diagnosis_research_subject_df(source, cohort_name)\n        specimen_df = self.get_specimen_df(source, cohort_name)\n        treatment_df = self.get_treatment_df(source, cohort_name)\n        subj_rsub_df = self.get_merged_subject_research_subject_df(source, cohort_name)\n\n        # Now use the CdaFactory classes to transform the information from the DataFrames into\n        # components of the GA4GH Phenopacket Schema\n        # Add these components one at a time to Phenopacket objects.\n\n        # treatment_factory = TODO\n\n        print(\"\\nConverting to Phenopackets...\\n\")\n\n        # Retrieve GA4GH Individual messages\n        for _, row in tqdm(subject_df.iterrows(),total=len(subject_df), desc= \"individual dataframe\"):\n            try:\n                individual_message = self._individual_factory.to_ga4gh(row=row)\n            except ValueError as e:\n                # TODO: decide how to handle depending on your paranoia\n                #\n                pass\n\n            individual_id = individual_message.id\n            ppackt = PPkt.Phenopacket()\n            ppackt.id = f'{cohort_name}-{individual_id}'\n            ppackt.subject.CopyFrom(individual_message)\n            ppackt_d[individual_id] = ppackt\n\n        # Retrieve GA4GH Disease messages\n        for _, row in tqdm(diag_rsub_df.iterrows(), total= len(diag_rsub_df.index), desc=\"merged diagnosis and researchsubject dataframe\"):\n            disease_message = self._disease_factory.to_ga4gh(row)\n            #print(row)\n            pp = ppackt_d.get(row[\"subject_id\"]) \n\n            # Do not add the disease if it is already in the phenopacket.\n            if not any(disease.term.id == disease_message.term.id for disease in pp.diseases):\n                pp.diseases.append(disease_message)\n\n        # Retrieve GA4GH Biospecimen messages\n        for idx, row in tqdm(specimen_df.iterrows(),total= len(specimen_df.index), desc=\"specimen/biosample dataframe\"):\n            biosample_message = self._specimen_factory.to_ga4gh(row)\n            individual_id = row[\"subject_id\"]\n            if individual_id not in ppackt_d:\n                raise ValueError(f\"Attempt to enter unknown individual ID from biosample factory: \\\"{individual_id}\\\"\")\n\n            # convert CDA days_to_collection to PPKt time_of_collection\n            #         days_to_collection: number of days from index date to sample collection date\n            #         time_of_collection: Age of subject at time sample was collected \n            if not pd.isna(row['days_to_collection']):\n                days_to_coll_iso = CdaFactory.days_to_iso(int(row[\"days_to_collection\"]))\n            # this should work if both are pd.Timedelta:\n            # TODO: fix the code below!\n            # time_of_collection = ppackt_d[individual_id][\"iso8601duration\"] + days_to_coll_iso # should it be 'Age' or 'iso8601duration'?\n            # biosample_message[\"time_of_collection\"] = time_of_collection\n\n            ppackt_d.get(individual_id).biosamples.append(biosample_message)\n\n        # Get variant data for each ResearchSubject in Subject\n        # takes 45 minutes due to API calls to gdc\n        for _, row in tqdm(subj_rsub_df.iterrows(), total=subj_rsub_df.shape[0], desc=\"subject researchsubject dataframe\"):\n            individual_id = row[\"subject_id\"]\n            # removing this loop for new CDA API.  Should work the same to go through df by row (MS 4-10-24)\n            #  Note: as of 4-10-24, no way to access system/data source from result of fetch_rows (can specify in fetch_rows)\n            #for rsub_subj in row[\"subject_identifier\"]:\n            #    if rsub_subj[\"system\"] == \"GDC\":\n\n            # have to strip off the leading name before first period\n            # e.g. TCGA.TCGA-05-4250 -&gt; TCGA-05-4250\n            subj_id = re.sub(\"^[^.]+\\.\", \"\", row[\"subject_id\"])\n            #print(row[\"subject_id\"], subj_id)\n\n            variant_interpretations = self._gdc_mutation_service.fetch_variants(subj_id) # was rsub_subj['value']\n            vital_status = self._gdc_mutation_service.fetch_vital_status(subj_id)\n            if len(variant_interpretations) == 0:\n                #print(\"No variants found\")\n                continue\n            ppackt_d.get(individual_id).subject.vital_status.CopyFrom(vital_status)\n            #else:\n                #print(\"length variant_interpretations: {}\".format(len(variant_interpretations)))\n\n            # TODO: improve/enhance diagnosis term annotations\n            diagnosis = PPkt.Diagnosis()\n            diagnosis.disease.id = \"NCIT:C3262\"\n            diagnosis.disease.label = \"Neoplasm\"\n\n            for variant in variant_interpretations:\n                genomic_interpretation = PPkt.GenomicInterpretation()\n                genomic_interpretation.subject_or_biosample_id = row[\"subject_id\"]\n                genomic_interpretation.interpretation_status = PPkt.GenomicInterpretation.InterpretationStatus.UNKNOWN_STATUS\n                genomic_interpretation.variant_interpretation.CopyFrom(variant)\n\n                diagnosis.genomic_interpretations.append(genomic_interpretation)\n\n            interpretation = PPkt.Interpretation()\n            interpretation.id = f\"{individual_id}-{row['researchsubject_id']}\"\n            interpretation.progress_status = PPkt.Interpretation.ProgressStatus.IN_PROGRESS \n            interpretation.diagnosis.CopyFrom(diagnosis)\n\n            ppackt_d.get(individual_id).interpretations.append(interpretation)\n\n        # TODO Treatment\n        # make_cda_medicalaction\n        for idx, row in tqdm(treatment_df.iterrows(), total=len(treatment_df.index), desc=\"Treatment DF\"):\n            individual_id = row[\"subject_id\"]\n            medical_action_message = make_cda_medicalaction(row)\n            if individual_id not in ppackt_d:\n                raise ValueError(f\"Attempt to enter unknown individual ID from treatment factory: \\\"{individual_id}\\\"\")\n            ppackt_d.get(individual_id).medical_actions.append(medical_action_message)\n\n        # When we get here, we have constructed GA4GH Phenopackets with Individual, Disease, Biospecimen, MedicalAction, and GenomicInterpretations\n        return list(ppackt_d.values())\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncoexporter.cda.CdaTableImporter.get_ga4gh_phenopackets","title":"<code>get_ga4gh_phenopackets(source, **kwargs)</code>","text":"<p>Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.</p> <p>Returns:</p> Type Description <code>typing.List[PPkt.Phenopacket]  New version of CDA: need to change Q to fetch_rows()</code> <p>A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.</p> Source code in <code>src/oncoexporter/cda/cda_table_importer.py</code> <pre><code>def get_ga4gh_phenopackets(self, source: dict, **kwargs) -&gt; typing.List[PPkt.Phenopacket]:\n    \"\"\"Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.\n\n    :returns: A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.\n    :rtype: typing.List[PPkt.Phenopacket]\n\n    New version of CDA: need to change Q to fetch_rows()\n    \"\"\"\n    # no longer using Q objects\n    # if not isinstance(source, Q):\n    #    raise ValueError(f\"query_obj argument must be Q.Q object, but instead was {type(source)}\")\n\n    if 'cohort_name' in kwargs:\n        cohort_name = kwargs['cohort_name']\n    else:\n        # Format it as a string, for example: 'YYYY-MM-DD HH:MM:SS'\n        ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n        cohort_name = f'cohort-{ts}'\n\n    # Dictionary of phenopackets, keys are the phenopacket ids.\n    ppackt_d = {}\n\n    # First obtain the pandas DataFrames from the CDA tables with rows that correspond to the Query\n    subject_df = self._get_subject_df(source, cohort_name)\n    diag_rsub_df = self.get_merged_diagnosis_research_subject_df(source, cohort_name)\n    specimen_df = self.get_specimen_df(source, cohort_name)\n    treatment_df = self.get_treatment_df(source, cohort_name)\n    subj_rsub_df = self.get_merged_subject_research_subject_df(source, cohort_name)\n\n    # Now use the CdaFactory classes to transform the information from the DataFrames into\n    # components of the GA4GH Phenopacket Schema\n    # Add these components one at a time to Phenopacket objects.\n\n    # treatment_factory = TODO\n\n    print(\"\\nConverting to Phenopackets...\\n\")\n\n    # Retrieve GA4GH Individual messages\n    for _, row in tqdm(subject_df.iterrows(),total=len(subject_df), desc= \"individual dataframe\"):\n        try:\n            individual_message = self._individual_factory.to_ga4gh(row=row)\n        except ValueError as e:\n            # TODO: decide how to handle depending on your paranoia\n            #\n            pass\n\n        individual_id = individual_message.id\n        ppackt = PPkt.Phenopacket()\n        ppackt.id = f'{cohort_name}-{individual_id}'\n        ppackt.subject.CopyFrom(individual_message)\n        ppackt_d[individual_id] = ppackt\n\n    # Retrieve GA4GH Disease messages\n    for _, row in tqdm(diag_rsub_df.iterrows(), total= len(diag_rsub_df.index), desc=\"merged diagnosis and researchsubject dataframe\"):\n        disease_message = self._disease_factory.to_ga4gh(row)\n        #print(row)\n        pp = ppackt_d.get(row[\"subject_id\"]) \n\n        # Do not add the disease if it is already in the phenopacket.\n        if not any(disease.term.id == disease_message.term.id for disease in pp.diseases):\n            pp.diseases.append(disease_message)\n\n    # Retrieve GA4GH Biospecimen messages\n    for idx, row in tqdm(specimen_df.iterrows(),total= len(specimen_df.index), desc=\"specimen/biosample dataframe\"):\n        biosample_message = self._specimen_factory.to_ga4gh(row)\n        individual_id = row[\"subject_id\"]\n        if individual_id not in ppackt_d:\n            raise ValueError(f\"Attempt to enter unknown individual ID from biosample factory: \\\"{individual_id}\\\"\")\n\n        # convert CDA days_to_collection to PPKt time_of_collection\n        #         days_to_collection: number of days from index date to sample collection date\n        #         time_of_collection: Age of subject at time sample was collected \n        if not pd.isna(row['days_to_collection']):\n            days_to_coll_iso = CdaFactory.days_to_iso(int(row[\"days_to_collection\"]))\n        # this should work if both are pd.Timedelta:\n        # TODO: fix the code below!\n        # time_of_collection = ppackt_d[individual_id][\"iso8601duration\"] + days_to_coll_iso # should it be 'Age' or 'iso8601duration'?\n        # biosample_message[\"time_of_collection\"] = time_of_collection\n\n        ppackt_d.get(individual_id).biosamples.append(biosample_message)\n\n    # Get variant data for each ResearchSubject in Subject\n    # takes 45 minutes due to API calls to gdc\n    for _, row in tqdm(subj_rsub_df.iterrows(), total=subj_rsub_df.shape[0], desc=\"subject researchsubject dataframe\"):\n        individual_id = row[\"subject_id\"]\n        # removing this loop for new CDA API.  Should work the same to go through df by row (MS 4-10-24)\n        #  Note: as of 4-10-24, no way to access system/data source from result of fetch_rows (can specify in fetch_rows)\n        #for rsub_subj in row[\"subject_identifier\"]:\n        #    if rsub_subj[\"system\"] == \"GDC\":\n\n        # have to strip off the leading name before first period\n        # e.g. TCGA.TCGA-05-4250 -&gt; TCGA-05-4250\n        subj_id = re.sub(\"^[^.]+\\.\", \"\", row[\"subject_id\"])\n        #print(row[\"subject_id\"], subj_id)\n\n        variant_interpretations = self._gdc_mutation_service.fetch_variants(subj_id) # was rsub_subj['value']\n        vital_status = self._gdc_mutation_service.fetch_vital_status(subj_id)\n        if len(variant_interpretations) == 0:\n            #print(\"No variants found\")\n            continue\n        ppackt_d.get(individual_id).subject.vital_status.CopyFrom(vital_status)\n        #else:\n            #print(\"length variant_interpretations: {}\".format(len(variant_interpretations)))\n\n        # TODO: improve/enhance diagnosis term annotations\n        diagnosis = PPkt.Diagnosis()\n        diagnosis.disease.id = \"NCIT:C3262\"\n        diagnosis.disease.label = \"Neoplasm\"\n\n        for variant in variant_interpretations:\n            genomic_interpretation = PPkt.GenomicInterpretation()\n            genomic_interpretation.subject_or_biosample_id = row[\"subject_id\"]\n            genomic_interpretation.interpretation_status = PPkt.GenomicInterpretation.InterpretationStatus.UNKNOWN_STATUS\n            genomic_interpretation.variant_interpretation.CopyFrom(variant)\n\n            diagnosis.genomic_interpretations.append(genomic_interpretation)\n\n        interpretation = PPkt.Interpretation()\n        interpretation.id = f\"{individual_id}-{row['researchsubject_id']}\"\n        interpretation.progress_status = PPkt.Interpretation.ProgressStatus.IN_PROGRESS \n        interpretation.diagnosis.CopyFrom(diagnosis)\n\n        ppackt_d.get(individual_id).interpretations.append(interpretation)\n\n    # TODO Treatment\n    # make_cda_medicalaction\n    for idx, row in tqdm(treatment_df.iterrows(), total=len(treatment_df.index), desc=\"Treatment DF\"):\n        individual_id = row[\"subject_id\"]\n        medical_action_message = make_cda_medicalaction(row)\n        if individual_id not in ppackt_d:\n            raise ValueError(f\"Attempt to enter unknown individual ID from treatment factory: \\\"{individual_id}\\\"\")\n        ppackt_d.get(individual_id).medical_actions.append(medical_action_message)\n\n    # When we get here, we have constructed GA4GH Phenopackets with Individual, Disease, Biospecimen, MedicalAction, and GenomicInterpretations\n    return list(ppackt_d.values())\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncoexporter.cda.CdaTableImporter.get_merged_diagnosis_research_subject_df","title":"<code>get_merged_diagnosis_research_subject_df(q, cohort_name)</code>","text":"<p>Retrieve a merged dataframe from CDA corresponding to the diagnosis and research subject tables</p> <p>diagnosis table columns: diagnosis_id, age_at_diagnosis, grade, method_of_diagnosis, morphology, primary_diagnosis, stage</p> <p>researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition, primary_diagnosis_site</p> <p>Need to combine in order to get primary_diagnosis_condition and primary_diagnosis_site with diagnosis table</p> <p>Original: diagnosis_callable = lambda: q.diagnosis.run(page_size=self._page_size).get_all().to_dataframe() diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\") print(\"obtained diagnosis_df\")</p> <p>rsub_callable = lambda: q.researchsubject.run(page_size=self._page_size).get_all().to_dataframe() research_subject_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_research_subject_df.pkl\") print(\"obtained research_subject_df\")</p> <p>merged_df = pd.merge(diagnosis_df, research_subject_df, left_on='researchsubject_id', right_on='researchsubject_id',                      suffixes=[\"_di\", \"_rs\"]) return merged_df</p> Source code in <code>src/oncoexporter/cda/cda_table_importer.py</code> <pre><code>def get_merged_diagnosis_research_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieve a merged dataframe from CDA corresponding to the diagnosis and research subject tables\n\n    diagnosis table columns: diagnosis_id, age_at_diagnosis, grade, method_of_diagnosis, morphology, primary_diagnosis, stage\n\n    researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition, primary_diagnosis_site\n\n    Need to combine in order to get primary_diagnosis_condition and primary_diagnosis_site with diagnosis table\n\n    Original:\n    diagnosis_callable = lambda: q.diagnosis.run(page_size=self._page_size).get_all().to_dataframe()\n    diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\")\n    print(\"obtained diagnosis_df\")\n\n    rsub_callable = lambda: q.researchsubject.run(page_size=self._page_size).get_all().to_dataframe()\n    research_subject_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_research_subject_df.pkl\")\n    print(\"obtained research_subject_df\")\n\n    merged_df = pd.merge(diagnosis_df, research_subject_df, left_on='researchsubject_id', right_on='researchsubject_id',\n                         suffixes=[\"_di\", \"_rs\"])\n    return merged_df\n\n    \"\"\"\n    print(\"\\nGetting merged diagnosis and researchsubject df...\")\n    diagnosis_callable = lambda: fetch_rows( table='diagnosis', **q , add_columns=['subject_id'])\n    diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\")\n    print(\"obtained diagnosis_df\")\n    #diagnosis_df.to_csv('diagnosis_df.txt', sep='\\t')\n\n    # tried link_to_table='diagnosis' but it doesn't add any columns\n    rsub_callable = lambda: fetch_rows( table='researchsubject', **q , add_columns=['subject_id'])\n    rsub_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_researchsubject_df.pkl\") # call is repeated below in get_merged_subject_research_subject_df\n    print(\"obtained researchsubject_df\")\n    #rsub_df.to_csv('rsub_diagnosis_df.txt', sep='\\t')\n\n    # merge tables\n    diag_rsub_df = pd.merge(diagnosis_df, rsub_df, left_on='subject_id', right_on='subject_id') #, suffixes=[\"_di\", \"_rs\"])\n    print(\"obtained merged diagnosis researchsubject df\")\n    #diag_rsub_df.to_csv('diagnosis_rsub.txt', sep='\\t')\n\n    return diag_rsub_df\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncoexporter.cda.CdaTableImporter.get_merged_subject_research_subject_df","title":"<code>get_merged_subject_research_subject_df(q, cohort_name)</code>","text":"<p>Retrieve a merged dataframe from CDA corresponding to the subject and research subject tables Need both subject_id and researchsubject_id to include variants in phenopacket </p> <p>subject table columns: subject_id, cause_of_death, days_to_birth, days_to_death, ethnicity, race                        sex, species, vital_status</p> <p>researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition,                                  primary_diagnosis_site</p> <p>M. Sierk 4-11-24:      This is how Henry Schaeffer from CBIIT recommended getting the data source:</p> <pre><code>I consolidate the data_source_id columns (as opposed to just deleting it which works also) or else \nthe merge expands each subject into many more rows. For example, for subject provenance I used:\n\nsub = fetch_rows(table='subject', provenance=True)\nsub['subject_data_source_id_concat'] = sub.groupby(['subject_id','subject_data_source'])['subject_data_source_id'].transform(lambda x: ','.join(x))\nsub = sub.drop(columns=['subject_data_source_id'], axis=1)\nsub = sub.drop_duplicates()\n</code></pre> Source code in <code>src/oncoexporter/cda/cda_table_importer.py</code> <pre><code>def get_merged_subject_research_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieve a merged dataframe from CDA corresponding to the subject and research subject tables\n    Need both subject_id and researchsubject_id to include variants in phenopacket \n\n    subject table columns: subject_id, cause_of_death, days_to_birth, days_to_death, ethnicity, race\n                           sex, species, vital_status\n\n    researchsubject table columns: researchsubject_id, member_of_research_project, primary_diagnosis_condition, \n                                    primary_diagnosis_site\n\n    M. Sierk 4-11-24: \n        This is how Henry Schaeffer from CBIIT recommended getting the data source:\n\n        I consolidate the data_source_id columns (as opposed to just deleting it which works also) or else \n        the merge expands each subject into many more rows. For example, for subject provenance I used:\n\n        sub = fetch_rows(table='subject', provenance=True)\n        sub['subject_data_source_id_concat'] = sub.groupby(['subject_id','subject_data_source'])['subject_data_source_id'].transform(lambda x: ','.join(x))\n        sub = sub.drop(columns=['subject_data_source_id'], axis=1)\n        sub = sub.drop_duplicates()\n\n    \"\"\"\n    print(\"\\nGetting merged subject and researchsubject df...\")\n    #subject_callable = lambda: q.subject.run(page_size=self._page_size).get_all().to_dataframe()\n\n    subject_callable = lambda: fetch_rows( table='subject', **q ) # link_to_table='researchsubject' doesn't add anything\n    subject_df = self._get_cda_df(subject_callable, f\"{cohort_name}_subject_df.pkl\")\n\n    rsub_callable = lambda: fetch_rows( table='researchsubject', **q , add_columns=['subject_id']) # repeat from above\n    rsub_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_researchsubject_df.pkl\")\n\n    # merge tables\n    subject_rsub_df = pd.merge(subject_df, rsub_df, left_on='subject_id', right_on='subject_id') #, suffixes=[\"_di\", \"_rs\"])\n    print(\"obtained merged subject and researchsubject df\")\n    #subject_rsub_df.to_csv('subject_rsub_df.txt', sep='\\t')\n\n\n    #rsub_callable = lambda: q.researchsubject.run(page_size=self._page_size).get_all().to_dataframe()\n    #rsub_callable = lambda: fetch_rows( table='researchsubject', **q , link_to_table='subject' )\n    #research_subject_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_research_subject_df.pkl\")\n    #print(\"obtained research_subject_df\")\n    #merged_df = pd.merge(subject_df, research_subject_df, left_on='subject_id', right_on='subject_id',\n                            #suffixes=[\"_subj\", \"_rs\"])\n    #research_subject_df.to_csv('researchsubject_df.txt', sep='\\t')\n\n    return subject_rsub_df\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncoexporter.cda.CdaTableImporter.get_specimen_df","title":"<code>get_specimen_df(q, cohort_name)</code>","text":"<p>Retrieve the subject dataframe from CDA</p> <p>This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pandas DataFrame that corresponds to the CDA subject table.</p> Source code in <code>src/oncoexporter/cda/cda_table_importer.py</code> <pre><code>def get_specimen_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieve the subject dataframe from CDA\n\n    This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n    :raises: raises an exception if the query object was not properly initialized\n    :returns: pandas DataFrame that corresponds to the CDA subject table.\n    :rtype: pd.DataFrame\n    \"\"\"\n    print(\"\\nGetting specimen df...\")\n    #specimen_callable = lambda: q.specimen.run(page_size=self._page_size).get_all().to_dataframe()\n    specimen_callable = lambda: fetch_rows( table='specimen', **q, add_columns=['subject_id'] )\n    specimen_df = self._get_cda_df(specimen_callable, f\"{cohort_name}_specimen_df.pkl\")\n    #specimen_df.to_csv('specimen_df.txt', sep='\\t')\n    return specimen_df\n</code></pre>"},{"location":"explanations/cda_disease/","title":"CDA Disease","text":"<p>We extract information about the disease diagnosis from two CDA tables, <code>diagnosis</code> and <code>researchsubject</code>. We first summarize the tables and then outline our ETL strategy.</p>"},{"location":"explanations/cda_disease/#diagnosis","title":"diagnosis","text":"Column Example Explanation diagnosis_id CGCI-HTMCP-CC.HTMCP-03-06-02424.HTMCP-03-06-02424_diagnosis y diagnosis_identifier see below y primary_diagnosis Squamous cell carcinoma, keratinizing, NOS y age_at_diagnosis 13085.0 y morphology 8071/3 y stage None y grade G3 y method_of_diagnosis Biopsy y subject_id CGCI.HTMCP-03-06-02424 y researchsubject_id CGCI-HTMCP-CC.HTMCP-03-06-02424 y <p>The fields of the table have the following meaning.</p> <ul> <li>diagnosis_id Question: It seems as if this identifier has some syntex of meaning or is it random?</li> <li>diagnosis_identifier Question: This field seems to have a lot of structure. How is it used in CDA and is there documentation on how to interpret it? This field has the following structure. <pre><code>[{'system': 'GDC',\n  'field_name': 'case.diagnoses.diagnosis_id',\n  'value': '06af070e-aad4-5b2d-a693-b6ccfe93985a'},\n {'system': 'GDC',\n  'field_name': 'case.diagnoses.submitter_id',\n  'value': 'HTMCP-03-06-02424_diagnosis'}]\n</code></pre></li> <li>primary_diagnosis This field represents the main cancer diagnosis of this individual</li> <li>age_at_diagnosis This field represents the number of days of life of the individual on the day during which the cancer diagnosis was made.</li> <li>morphology Entries such as <code>8071/3</code> are ICD-O codes. TODO - translate into ontology codes.</li> <li>stage Cancer stage.</li> <li>grade Cancer grade. Note that in many tables there are strings such as G3. NCIT has more detailed terms, but we think it best to stick to the top level, and possible consider postcomposition to represent specific stage systems.</li> <li>method_of_diagnosis This corresponds to</li> <li>subject_id Identifier for the individual being investigated</li> <li>researchsubject_id Identifier for the researchsubject (which can be a sample or an individaul - Question: where is this documented?)</li> </ul>"},{"location":"explanations/cda_disease/#researchsubject","title":"researchsubject","text":"Column Example Explanation researchsubject_id CPTAC-3.C3L-00563 y researchsubject_identifier see below y member_of_research_project CPTAC-3 y primary_diagnosis_condition Adenomas and Adenocarcinomas y primary_diagnosis_site Uterus, NOS y subject_id CPTAC.C3L-00563 y <ul> <li>researchsubject_id xyz</li> <li> <p>researchsubject_identifier Question: How do we interpret this kind of structure: <pre><code>[{'system': 'GDC',\n  'field_name': 'case.case_id',\n  'value': '2b1894fb-b168-42ca-942f-a5def0bb8309'},\n {'system': 'GDC', 'field_name': 'case.submitter_id', 'value': 'C3L-00563'}]\n</code></pre></p> </li> <li> <p>member_of_research_project Question: Where do we get more information about the research projects? What informationis available?</p> </li> <li>primary_diagnosis_condition Question: This seems to be duplicative with the field <code>primary_diagnosis</code> in the diagnosis table. What is the difference?</li> <li>primary_diagnosis_site Todo - we can map this to uberon</li> <li>subject_id This relates to the subject_id in other tables.</li> </ul>"},{"location":"explanations/cda_disease/#mapping-strategy","title":"Mapping strategy","text":"<p>We merge the diagnosis and researchsubject tables to retrieve all needed information about the disease diagnosis.</p> Merging diagnosis and researchsubject via the researchsubject_id<pre><code>merged_df = pd.merge(diagnosis_df,\n                    rsub_df,\n                    left_on='researchsubject_id',\n                    right_on='researchsubject_id',\n                    suffixes=[\"_di\", \"_rs\"])\n</code></pre>"},{"location":"explanations/cda_mutation/","title":"CDA Mutation","text":"<p>We extract information about variants from the CDA table <code>mutation</code>. We first summarize the table and then outline our ETL strategy.</p> Column Example Explanation project_short_name TCGA-CESC case_barcode TCGA-C5-A1MI cda_subject_id TCGA.TCGA-C5-A1MI primary_site Cervix uteri Hugo_Symbol IGSF9B Entrez_Gene_Id 22997 Center BI NCBI_Build GRCh38 Chromosome chr11 Start_Position 133921225 End_Position 133921225 Strand + Variant_Classification Missense_Mutation Variant_Type SNP Reference_Allele C Tumor_Seq_Allele1 C Tumor_Seq_Allele2 T dbSNP_RS rs771150072 dbSNP_Val_Status Tumor_Aliquot_Barcode TCGA-C5-A1MI-01A-11D-A14W-08 Matched_Norm_Aliquot_Barcode TCGA-C5-A1MI-10A-01D-A14W-08 Match_Norm_Seq_Allele1 Match_Norm_Seq_Allele2 Tumor_Validation_Allele1 Tumor_Validation_Allele2 Match_Norm_Validation_Allele1 Match_Norm_Validation_Allele2 Verification_Status Validation_Status Mutation_Status Somatic Sequencing_Phase Sequence_Source Validation_Method Score BAM_File Sequencer Tumor_Aliquot_UUID 497c20f0-8a42-4d20-abdc-0415982ebb9f Matched_Norm_Aliquot_UUID a3d0503b-baac-4f83-9182-be7b4154c61d HGVSc c.2500G&gt;A HGVSp p.Val834Met HGVSp_Short p.V834M Transcript_ID ENST00000321016 Exon_Number 18/19 t_depth 64 t_ref_count 43 t_alt_count 20 n_depth 88 n_ref_count n_alt_count all_effects IGSF9B,missense_variant,p.V834M,ENST00000533871,NM_001277285.4,c.2500G&gt;A,MODERATE,YES,deleterious(0),probably_damaging(1),-1;IGSF9B,missense_variant,p.V834M,ENST00000321016,,c.2500G&gt;A,MODERATE,,deleterious(0.01),probably_damaging(0.988),-1;IGSF9B,downstream_gene_variant,,ENST00000527648,,,MODIFIER,,,,-1 Allele T Gene ENSG00000080854 Feature ENST00000321016 Feature_type Transcript One_Consequence missense_variant Consequence missense_variant cDNA_position 2500/4050 Protein_position 834/1349 Amino_acids V/M Codons Gtg/Atg Existing_variation rs771150072;COSV58068494 DISTANCE TRANSCRIPT_STRAND -1 SYMBOL IGSF9B SYMBOL_SOURCE HGNC HGNC_ID HGNC:32326 BIOTYPE protein_coding CANONICAL CCDS ENSP ENSP00000317980 SWISSPROT Q9UPX0.150 TREMBL UNIPARC UPI0001545E3E UNIPROT_ISOFORM Q9UPX0-1 RefSeq MANE APPRIS FLAGS SIFT deleterious(0.01) PolyPhen probably_damaging(0.988) EXON 18/19 INTRON DOMAINS PANTHER:PTHR12231;PANTHER:PTHR12231:SF240;Low_complexity_(Seg):seg ThousG_AF ThousG_AFR_AF ThousG_AMR_AF ThousG_EAS_AF ThousG_EUR_AF ThousG_SAS_AF ESP_AA_AF ESP_EA_AF gnomAD_AF 1.216e-05 gnomAD_AFR_AF gnomAD_AMR_AF gnomAD_ASJ_AF gnomAD_EAS_AF gnomAD_FIN_AF gnomAD_NFE_AF gnomAD_OTH_AF gnomAD_SAS_AF MAX_AF 9.968e-05 MAX_AF_POPS 3.278e-05 gnomAD_non_cancer_AF gnomAD_non_cancer_AFR_AF gnomAD_non_cancer_AMI_AF gnomAD_non_cancer_AMR_AF gnomAD_non_cancer_ASJ_AF gnomAD_non_cancer_EAS_AF gnomAD_non_cancer_FIN_AF gnomAD_non_cancer_MID_AF gnomAD_non_cancer_NFE_AF gnomAD_non_cancer_OTH_AF gnomAD_non_cancer_SAS_AF gnomAD_non_cancer_MAX_AF_adj gnomAD_non_cancer_MAX_AF_POPS_adj CLIN_SIG SOMATIC 0;1 PUBMED TRANSCRIPTION_FACTORS MOTIF_NAME MOTIF_POS HIGH_INF_POS MOTIF_SCORE_CHANGE miRNA IMPACT MODERATE PICK VARIANT_CLASS SNV TSL 5 HGVS_OFFSET PHENO 0;1 GENE_PHENO CONTEXT GGCCACGCTGT tumor_submitter_uuid 8c3559db-155f-42d3-9a73-38d5610f74b5 normal_submitter_uuid 59778b5f-335a-471e-abb2-6dde0b5d7fe7 case_id 941f75a1-fea4-4539-ba69-60bb11608f6d GDC_FILTER COSMIC COSM376595;COSM376596 hotspot False RNA_Support Unknown RNA_depth RNA_ref_count RNA_alt_count callers muse;mutect2;varscan2 file_gdc_id 3fd5afe7-9e69-4ea8-ab01-80e41783d795 muse Yes mutect2 Yes pindel No varscan2 Yes sample_barcode_tumor TCGA-C5-A1MI-01A sample_barcode_normal TCGA-C5-A1MI-10A aliquot_barcode_tumor TCGA-C5-A1MI-01A-11D-A14W-08 aliquot_barcode_normal TCGA-C5-A1MI-10A-01D-A14W-08 <p>We will use only a few fields for extracting data for the phenopacket. These fields are explained below.</p>"},{"location":"model/","title":"oncopacket: Model","text":"<p>The model module of oncopacket contains classes that are flexible data models that can be constructed with data from various upstream sources, and can then be used to export data in GA4GH Phenopacket format.</p>"},{"location":"model/op_individual/","title":"OpIndividual","text":"<p>               Bases: <code>OpMessage</code></p> <p>This class represents the individual or patient who is the subject of the phenopacket. It provides a DTO-like object to hold data that should be instantiated by factory methods corresponding to the data source. THe class can generate a GA4GH Phenopakcet Schema Individual message.</p> <p>Note that we assume the species is always human, so taxonomy is always set to 9606 Homo sapiens</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>the individual identifier (application-specific)</p> required <code>alternate_ids</code> <code>list</code> <p>list of alternative identifiers, optional</p> <code>[]</code> <code>date_of_birth</code> <code>timestamp, optional</code> <p>date of birth of the individual (optional, should not be used without data privacy protection)</p> <code>None</code> <code>iso8601duration</code> <code>str</code> <p>age represented as an ISO 8601 Period, e.g., P42Y5M would be 42 years and 5 months</p> <code>None</code> <code>vital_status</code> <code>PPkt.VitalStatus</code> <p>An object representing the Vital status of the individual, optional</p> <code>None</code> <code>karyotypic_sex</code> <p>the chromosomal sex (karyotypic sex), of the individual, e.g., XY or XX or XXY, optional</p> <code>None</code> <code>gender</code> <p>the self-described gender of the individual, optional</p> <code>None</code> Source code in <code>src/oncoexporter/model/op_Individual.py</code> <pre><code>class OpIndividual(OpMessage):\n    \"\"\"\n    This class represents the individual or patient who is the subject of the phenopacket.\n    It provides a DTO-like object to hold data that should be instantiated by factory methods\n    corresponding to the data source. THe class can generate a GA4GH Phenopakcet Schema Individual message.\n\n    Note that we assume the species is always human, so taxonomy is always set to\n    9606 Homo sapiens\n\n    :param id: the individual identifier (application-specific)\n    :type id: str\n    :param alternate_ids: list of alternative identifiers, optional\n    :type alternate_ids: list\n    :param date_of_birth: date of birth of the individual (optional, should not be used without data privacy protection)\n    :type date_of_birth: timestamp, optional\n    :param iso8601duration: age represented as an ISO 8601 Period, e.g., P42Y5M would be 42 years and 5 months\n    :type iso8601duration: str\n    :param vital_status: An object representing the Vital status of the individual, optional\n    :type vital_status: PPkt.VitalStatus\n    :param karyotypic_sex: the chromosomal sex (karyotypic sex), of the individual, e.g., XY or XX or XXY, optional\n    :param karyotypic_sex: str\n    :param gender: the self-described gender of the individual, optional\n\n    \"\"\"\n    def __init__(self, id,\n                alternate_ids = [],\n                date_of_birth=None,\n                iso8601duration=None,\n                vital_status=None,\n                sex=None,\n                karyotypic_sex=None,\n                gender=None) -&gt; None:\n        \"\"\"Constructor method\n        \"\"\"\n        self._id = id\n        # todo add check for date_of_birth, leaving out for now\n        self._iso8601duration = iso8601duration\n        male_sex = {\"m\", \"male\"}\n        female_sex = {\"f\",  \"female\",}\n        if sex.lower() in male_sex:\n            self._sex = PPkt.MALE\n        elif sex.lower() in female_sex:\n            self._sex = PPkt.FEMALE\n        else:\n            self._sex = PPkt.UNKNOWN_SEX\n\n        self._taxonomy = PPkt.OntologyClass()\n        self._taxonomy.id = \"NCBITaxon:9606\"\n        self._taxonomy.label = \"Homo sapiens\"\n\n        self._vital_status = vital_status\n\n\n    def to_ga4gh(self) -&gt; PPkt.Individual:\n        \"\"\"Transform the data in the onject into a GA4GH Phenopacket Individual\n        :return: An message corresponding to the GA4GH Phenopacket Individual\n        :rtype: PPkt.Individual\n        \"\"\"\n        individual =  PPkt.Individual()\n        individual.id = self._id\n        if self._iso8601duration is not None:\n            individual.time_at_last_encounter.age.iso8601duration = self._iso8601duration\n        individual.sex = self._sex\n        if self._taxonomy is not None:\n            individual.taxonomy.CopyFrom(self._taxonomy)\n        if self._vital_status is not None:\n            individual.vital_status.status = self._vital_status.status\n        return individual\n</code></pre>"},{"location":"model/op_individual/#src.oncoexporter.model.OpIndividual.__init__","title":"<code>__init__(id, alternate_ids=[], date_of_birth=None, iso8601duration=None, vital_status=None, sex=None, karyotypic_sex=None, gender=None)</code>","text":"<p>Constructor method</p> Source code in <code>src/oncoexporter/model/op_Individual.py</code> <pre><code>def __init__(self, id,\n            alternate_ids = [],\n            date_of_birth=None,\n            iso8601duration=None,\n            vital_status=None,\n            sex=None,\n            karyotypic_sex=None,\n            gender=None) -&gt; None:\n    \"\"\"Constructor method\n    \"\"\"\n    self._id = id\n    # todo add check for date_of_birth, leaving out for now\n    self._iso8601duration = iso8601duration\n    male_sex = {\"m\", \"male\"}\n    female_sex = {\"f\",  \"female\",}\n    if sex.lower() in male_sex:\n        self._sex = PPkt.MALE\n    elif sex.lower() in female_sex:\n        self._sex = PPkt.FEMALE\n    else:\n        self._sex = PPkt.UNKNOWN_SEX\n\n    self._taxonomy = PPkt.OntologyClass()\n    self._taxonomy.id = \"NCBITaxon:9606\"\n    self._taxonomy.label = \"Homo sapiens\"\n\n    self._vital_status = vital_status\n</code></pre>"},{"location":"model/op_individual/#src.oncoexporter.model.OpIndividual.to_ga4gh","title":"<code>to_ga4gh()</code>","text":"<p>Transform the data in the onject into a GA4GH Phenopacket Individual</p> <p>Returns:</p> Type Description <code>PPkt.Individual</code> <p>An message corresponding to the GA4GH Phenopacket Individual</p> Source code in <code>src/oncoexporter/model/op_Individual.py</code> <pre><code>def to_ga4gh(self) -&gt; PPkt.Individual:\n    \"\"\"Transform the data in the onject into a GA4GH Phenopacket Individual\n    :return: An message corresponding to the GA4GH Phenopacket Individual\n    :rtype: PPkt.Individual\n    \"\"\"\n    individual =  PPkt.Individual()\n    individual.id = self._id\n    if self._iso8601duration is not None:\n        individual.time_at_last_encounter.age.iso8601duration = self._iso8601duration\n    individual.sex = self._sex\n    if self._taxonomy is not None:\n        individual.taxonomy.CopyFrom(self._taxonomy)\n    if self._vital_status is not None:\n        individual.vital_status.status = self._vital_status.status\n    return individual\n</code></pre>"}]}